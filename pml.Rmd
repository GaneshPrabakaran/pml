---
title: "PML - Qualitative Activity Recognition"
author: "Ganesh Prabakaran"
date: "Saturday, June 20, 2015"
output: html_document
---

##
Abstract:
The goal of this project is to predict/classify the manner in which different people do their exercise.
The data for this project is collected from the measurements from fitness tracker devices and is taken from this source: http://groupware.les.inf.puc-rio.br/har. This model is built using Random Forest Algorithm.

##
Load necessary packages
```{r}

require(caret)
require(sqldf)
```
##
Analysis on Input files:
"pml-training.csv" and "pml-testing.csv" are the training and testing files respectively. Data preview shows the file containts missing values in the following forms - "NA", "#DIV/0!", "".

Lets read the input files with all NA strings.
```{r}
train_url <- url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
test_url <- url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")


rawtrain <-read.csv(train_url,na.strings=c("NA","","#DIV/0!"))
rawtest <-read.csv(test_url,na.strings=c("NA","","#DIV/0!"))


```

##
Analyze the missing values:
The features are extracted in the form of sliding window. One obeservation was the missing features were mainly on the derived features which were populted in the start/end of each new window. This can be visualized in the following manner.
```{r}

View(sqldf("select * from rawtrain order by num_window, user_name, raw_timestamp_part_1, raw_timestamp_part_2", row.names = FALSE))

View(sqldf("select * from rawtrain where new_window = 'yes'", row.names = FALSE))


View(sqldf("select * from rawtest order by num_window, user_name, raw_timestamp_part_1, raw_timestamp_part_2", row.names = FALSE))

```
The derived features describe the distribution function. One solution to fill the missing values could be deriving the features ourselves. However, the existing derived values does not seem to be correct. For example, consider column 'max_roll_belt'. The value -94.3 does not seem to aligned with roll_belt values in the range between 1 and 2.

Another observation here is that the test data do not have the entire time sliding window data to derive these features. Even if we dervie these missing values in train, we will not be able to do the same in the test data. Hence ignoring those derived columns would be the best option.

##
Feature selecction and data cleanup:

The columns -usernames, raw_timestamp_part_1, raw_timestamp_part_2, new_window, num_window does not seem to be relevant or help in prediction.

Also, the derived columns which has NA in all rows except new window row can be removed.
```{r}
irrelevant_col <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window")

m_train <- rawtrain[,!names(rawtrain) %in% irrelevant_col]
m_test <- rawtest[,!names(rawtest) %in% irrelevant_col]
                    
na_col <- apply(m_train, 2, function(x) {  sum(is.na(x))})
train <- m_train[, which(na_col == 0)]

test <- m_test[, which(na_col == 0)]
```

##
Cross Validation
Training data has enough volume for 80-20 split for cross validation. Based on the model performance we can switch to different split if needed.

```{r}


trainingIndex  <- createDataPartition(train$classe, p=.80, list=FALSE)
train_model <- train[ trainingIndex,]
train_cv  <- train[-trainingIndex,]

```

##
Model Creation

Lets try creating a model with randomForest method. Since it is one of decision tree approach, this does not require data standardization.

```{r}
rf_fit <- train(classe ~ .,train_model,method="rf",tuneGrid=data.frame(mtry=3),trControl=trainControl(method="cv"))

summary(rf_fit)
```


Check the model performance on out of sample (cross validation) data using confusionMatrix. 
```{r}
confusionMatrix(train_cv$classe,predict(rf_fit,train_cv))


```
Accuracy on Out of sample data as shown in the confusion Matrix is 99.64

Here is a list of the features with their importance in the model.
```{r}

varImp(rf_fit)
```
